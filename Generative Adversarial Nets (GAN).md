# Generative Adversarial Nets (GAN)



## Classification : Discrimitive vs. Generative

* **데이터를 어떻게 분류할 것인가**

  * Discrimitive model - Logistic Regression, Neural Network 등
  * Generative model - Naive Bayes, Gaussian Mixture Model(GMM) 등 

* **X에 대하여 X 가 어느 Y 클래스로 분류될 가능성이 큰가?**

  ***= P(Y|X)를 최대화 하는 Y를 찾는다.***

  

  ​		![img](https://t1.daumcdn.net/cfile/tistory/2139263C5192054629)'												

  [출처]: (http://sens.tistory.com/408)

  > ##### Discrimitive Model (판별 모델)
  >
  > - P(Y|X)를 <u>직접적으로 모델링</u>
  > - 학습데이터가 주어졌을 때, 주어진 데이터에 대해 최대가 되는 P(Y|X) 계산 
  > - 대표적으로, 최대우도추정(MLE), 손실함수(로그 손실함수) 사용

  > ##### Generative Model (생성 모델)
  >
  > * P(Y|X)를 직접적으로 구하지 않고 <u>베이즈 정리</u> 이용
  >
  > * P(X|Y)와 P(Y)를 각각 계산하여 베이즈 정리를 이용해 P(Y|X) 유도
  >
  >   - P(X|Y) :  각 클래스 Y에 대해 입력 X 가 나올 확률 모델링 (가우시안 분포, 베르누이 분포 등 이용)
  >
  >   - P(Y) : 각 클래스 Y가 나올 사전 확률 (훈련데이터에서의 Y의 빈도) 
  >
  >   cf. 베이즈 정리
  >   $$
  >   P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}
  >   $$



## GAN

* <u>**생성자(G)**</u> 와 <u>**판별자(D)**</u> 가 서로 상호작용(민맥스 게임)하여, 생성자가 더 정교한 데이터를 생성
  * **생성자(G)** : 실제 데이터처럼 보이는 가짜 데이터 생성
  * **판별자(D)** : 데이터가 실제인지 가짜인지 구분

### 1. 수학적 구조 

* **생성자**는 가짜 데이터를 실제 데이터처럼 보이게 하여 손실을 최소화 하고자 함
* **판별자**는 진짜 데이터를 올바르게 구분하고 가짜 데이터를 가짜로 분류하기 위한 **정확도를 최대화** 하고자 함

$$
\min_G \max_D V(D, G) = \mathbb{E}{x \sim p{\text{data}}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
$$

### 2. 학습 과정

<img src="/Users/airon/Library/Application Support/typora-user-images/image-20240912193116377.png" alt="image-20240912193116377" style="zoom:50%;" />

* 위 그림은 기존 생성 모델과 GAN의 과정차이의 이해를 돕기 위한 그림
* **생성자는 판별자가 가짜 데이터를 진짜라고 판단하도록 유도**
* **판별자는 주어진 데이터가 실제인지 가짜인지를 구분하는 정확도 최대화**
  * 단, 학습 초기 판별자가 너무 강한 잣대를 들이밀어 데이터를 판별하게되면, 유효한 학습을 할 수 없음
    * **log(1 - D(G(z)))** 대신 **log(D(G(z)))** 를 최대화하는 방식 사용
* **생성자와 판별자가 서로 민맥스 게임을 통해 더 나은 성능을 보이기 위해 경쟁**
  * 검은선 : 실제 데이터
  * 초록선 : 생성자가 생성한 데이터 분포
  * 파란선 : 판별자가 현제 데이터 분포를 보고 진짜 데이터일 확률을 추정한 값 

![image-20240912200102002](/Users/airon/Library/Application Support/typora-user-images/image-20240912200102002.png)

### 3. 결과

* **사용 데이터** 

  * MNIST

  * Tronto Face Database(TFD)

  * CIFAR-10

* **평가 방법**

  * 가우시안 파르젠 윈도우(Parzen Window) 기법 사용하여 데이터의 우도 추정하여 GAN이 우수한 성능을 보임을 확인

    > **Q. 데이터의 우도(likelihood)를 추정한다는 것은?**
    >
    > - 생성된 데이터를 기반으로 가우시안 분포(정규 분포) 함수를 만든다
    > - 각 가우시안 함수들의 합을 통해 실제 데이터의 분포 근사 판단
    > - 생성된 데이터의 분포가 실제 데이터의 분포를 얼마나 잘 따르는지를 판단

* **결과**

  * 학습 후 생성된 샘플을 시각화 한 결과, 생성자는 실제 데이터와 매우 유사한 데이터를 생성하는데 성공
  * 다음 그림은 훈련 샘플(training sample)을 기억하지 않고도, 랜덤 샘플이 얼마나 실제 데이터와 유사한 데이터를 만들어내는지 보여주기 위함

  ![image-20240912193905836](/Users/airon/Library/Application Support/typora-user-images/image-20240912193905836.png)

* **미래 연구** 

  * 조건부 GAN : 입력 조건을 추가하여 특정 속성에 맞는 데이터 생성
  * 반지도 학습 : 판별자에서 추출한 특징을 이용하여 데이터 학습에 이용
  * 효율성 개선 : GAN 학습 안정성과 효율성을 높이기 위한 연구(생성자와 판별자에 각기 다른 모델 사용)

  

### 4. 기존 모델링과의 비교

#### ➕ 장점 

- 마르코프 체인이나 근사 추론 없이도 학습 가능

  > **Q. 마르코프 체인을 사용한다는 것이 왜 큰 장점인가?**
  >
  > * 마르코프체인은 확률적 생성모델에서 학습이나 데이터 생성에 사용됨
  > * 마르코프 체인은 **이전 상태에 기반하여 다음 상태를 예측**하는 방식으로 데이터 확률 분포를 학습하기 위한 샘플링 반복적 수행
  >   * 반면 GAN은 Discriminator(판별자)가 **생성된 데이터가 실제 데이터와 얼마나 유사한지에 따른 판단**을 역전파로 Generator(생성자)에게 전달
  >   * 즉, 이전 Input 데이터가 다음 Input 데이터의 기반이 되느냐 되지 않느냐의 차이
  > * 이는 매우 많은 반복 작업을 요구하기 때문에 모델 훈련에 많은 시간이 걸림
  > * 이에 비해, **GAN**은 마르코프 체인이나 근사 추론을 사용하지 않고, 생성자와 판별자가 민맥스 게임이라는 경쟁을 통해 더나은 분류 성능을 가지도록 최적화
  >   * 이때, **생성자는 판별자를 속이기 위해 생성자 모델의 가중치를 조정**하여 실제 데이터에 가까운 분포를 생성하고자 함
  >   * **GAN은 기존 생성 모델과 달리 모델 훈련을 위한 반복작업을 수행하지 않고, 즉, 학습 과정의 효율성, 이전 결과값을 반영한 데이터 미생성 이라는 점에서 장점이 있음**

- 복잡하고 고차원적인 분포 모델링 가능
- 기존 방법에 비해 선명하고 사실적 데이터 생성

#### ➖단점

* 생성자와 판별자의 균형 조정이 필요

* 명시적 확률 모델이 없다는 점이 단점 (Generator와 Discriminator에 어떤 모델을 사용하는지에 따라 성능이 달라질 수 있음)

  